{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def feed_forward(inputs, outputs, weights):\n",
    "    pre_hidden = np.dot(inputs, weights[0]) + weights[1]\n",
    "    # Apply sigmoid\n",
    "    hidden = 1 / ( 1 + np.exp(-pre_hidden))\n",
    "    pred_out = np.dot(hidden, weights[2]) + weights[3]\n",
    "\n",
    "    mse = np.mean(np.square(pred_out - outputs))\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation Functions\n",
    "\n",
    "# Tanh\n",
    "def tanh(x):\n",
    "    return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.where(x > 0, x, 0)\n",
    "\n",
    "def linear(x):\n",
    "    return x\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[90m[\u001b[0m2025-11-23T03:55:48Z \u001b[32mINFO \u001b[0m re_grpc_server\u001b[90m]\u001b[0m Listening for gRPC connections on 0.0.0.0:9876. Connect by running `rerun --connect rerun+http://127.0.0.1:9876/proxy`\n",
      "/var/folders/py/f1p5p0jd5zv4xxm_q30gpf940000gn/T/ipykernel_36661/1587750079.py:10: DeprecationWarning: Use `set_time(timestamp=seconds)` or `set_time(duration=seconds)` instead.\n",
      "    See: https://www.rerun.io/docs/reference/migration/migration-0-23 for more details.\n",
      "  rr.set_time_seconds(\"t\", t )\n"
     ]
    }
   ],
   "source": [
    "# Rerun Demo of Activation\n",
    "import rerun as rr \n",
    "rr.init(\"learning/ml_vision/activations\", spawn=True)\n",
    "\n",
    "# Use time series as x-axis\n",
    "for i in range(-100, 100):\n",
    "    t = i / 1000.\n",
    "    \n",
    "    # Log each point with time as the x-axis\n",
    "    rr.set_time_seconds(\"t\", t )\n",
    "    rr.log(\"tanh\", rr.Scalars(tanh(t)))\n",
    "    rr.log(\"relu\", rr.Scalars(relu(t)))\n",
    "    rr.log(\"linear\", rr.Scalars(linear(t)))\n",
    "    rr.log(\"softmax\", rr.Scalars(softmax(t)))\n",
    "\n",
    "#rr.notebook_show(width=400, height=400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Functions\n",
    "\n",
    "def mse(p, y):\n",
    "    return np.mean(np.square(p - y))\n",
    "\n",
    "def mae(p, y):\n",
    "    return np.mean(np.abs(p - y))\n",
    "\n",
    "def binary_cross_entropy(p, y):\n",
    "    return -np.mean((y*np.log(p) + 1-y) * np.log(1-p))\n",
    "\n",
    "def categorical_cross_entropy(p, y):\n",
    "    return -np.mean(np.log(p[np.arrange(len(y)),y ]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/py/f1p5p0jd5zv4xxm_q30gpf940000gn/T/ipykernel_36661/2046863634.py:10: DeprecationWarning: Use `set_time(timestamp=seconds)` or `set_time(duration=seconds)` instead.\n",
      "    See: https://www.rerun.io/docs/reference/migration/migration-0-23 for more details.\n",
      "  rr.set_time_seconds(\"t\", t )\n"
     ]
    }
   ],
   "source": [
    "# Rerun Loss Demo\n",
    "import rerun as rr \n",
    "rr.init(\"learning/ml_vision/loss\", spawn=True)\n",
    "\n",
    "# Use time series as x-axis\n",
    "for i in range(-100, 100):\n",
    "    t = i / 1000\n",
    "    \n",
    "    # Log each point with time as the x-axis\n",
    "    rr.set_time_seconds(\"t\", t )\n",
    "    rr.log(\"tanh\", rr.Scalars(tanh(t)))\n",
    "    rr.log(\"relu\", rr.Scalars(relu(t)))\n",
    "    rr.log(\"linear\", rr.Scalars(linear(t)))\n",
    "    rr.log(\"softmax\", rr.Scalars(softmax(t)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Functions\n",
    "\n",
    "def mse(p, y):\n",
    "    return np.mean(np.square(p - y))\n",
    "\n",
    "def mae(p, y):\n",
    "    return np.mean(np.abs(p - y))\n",
    "\n",
    "def binary_cross_entropy(p, y):\n",
    "    return -np.mean((y*np.log(p) + 1-y) * np.log(1-p))\n",
    "\n",
    "def categorical_cross_entropy(p, y):\n",
    "    return -np.mean(np.log(p[np.arange(len(y)), y]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/py/f1p5p0jd5zv4xxm_q30gpf940000gn/T/ipykernel_36661/535189673.py:12: DeprecationWarning: Use `set_time(sequence=â€¦)` instead.\n",
      "    See: https://www.rerun.io/docs/reference/migration/migration-0-23 for more details.\n",
      "  rr.set_time_sequence(\"step\", i)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m p_cat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([p_clipped, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m p_clipped])\n\u001b[1;32m     22\u001b[0m y_cat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# convert to array for categorical_cross_entropy\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m rr\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_cross_entropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, rr\u001b[38;5;241m.\u001b[39mScalars(\u001b[43mcategorical_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_cat\u001b[49m\u001b[43m)\u001b[49m))\n",
      "Cell \u001b[0;32mIn[6], line 13\u001b[0m, in \u001b[0;36mcategorical_cross_entropy\u001b[0;34m(p, y)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcategorical_cross_entropy\u001b[39m(p, y):\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mlog(\u001b[43mp\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m]\u001b[49m))\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "import rerun as rr \n",
    "\n",
    "# Rerun Loss Demo\n",
    "rr.init(\"learning/ml_vision/loss_functions\", spawn=True)\n",
    "\n",
    "# Create sample predictions and ground truth for demonstration\n",
    "for i in range(1, 100):\n",
    "    p = i / 100.0  # prediction from 0.01 to 0.99\n",
    "    y = 0.5  # ground truth\n",
    "    \n",
    "    # Log each loss function with prediction as the x-axis\n",
    "    rr.set_time_sequence(\"step\", i)\n",
    "    rr.log(\"mae\", rr.Scalars(mae(p, y)))\n",
    "    \n",
    "    # For binary cross entropy, clip p to avoid log(0)\n",
    "    p_clipped = np.clip(p, 1e-7, 1 - 1e-7)\n",
    "    rr.log(\"binary_cross_entropy\", rr.Scalars(binary_cross_entropy(p_clipped, y)))\n",
    "    \n",
    "    # For categorical cross entropy, create sample probability distribution\n",
    "    # p_cat: probability distribution over classes (needs to be 2D for the function)\n",
    "    # y_cat: true class index\n",
    "    p_cat = np.array([[p_clipped, 1 - p_clipped]])  # Make it 2D\n",
    "    y_cat = np.array([0])  # true class index\n",
    "    rr.log(\"categorical_cross_entropy\", rr.Scalars(categorical_cross_entropy(p_cat, y_cat)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
